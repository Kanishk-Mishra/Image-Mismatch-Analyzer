# üß† AI-Based Mismatch Analyzer (Car's Dashboard Image Validation)

## üìò Problem Statement
In the automotive industry, validating dashboard and infotainment display images for multiple vehicle variants is crucial. Each test cycle generates a **Global Test Report** containing thousands of image comparisons between the *Reference (Expected)* and *To-Check (Actual)* images.  
Manual verification of mismatching pairs is time-consuming and error-prone.

The goal of this project is to **automate the semantic and visual comparison** of image pairs to classify them into one of four categories:
- ‚úÖ **OK** ‚Äì Images match perfectly or with negligible difference  
- ‚ö†Ô∏è **Investigate** ‚Äì Slight differences detected; human review recommended  
- ‚ùå **NOK** ‚Äì Major visual/semantic mismatch detected  
- üõë **Faulty** ‚Äì Missing or dimension-mismatched images

The output is an **AI-Annotated HTML Report** grouping results by status with a clickable summary table and an integrated feedback system.

---

## ‚öôÔ∏è Approach
The project leverages both **cloud and local AI models** to analyze mismatched image pairs extracted from `globalTestReport.html`.

1. **Input Parsing**  
   - Reads `globalTestReport.html` and extracts mismatched image pairs.  
   - Handles missing images and malformed HTML gracefully.

2. **AI-Based Comparison**  
   - If an API key for **Mistral** is available, sends both images for cloud-based semantic comparison.  
   - If not, falls back to a **local model** using pixel-level, color-difference, and cluster-based analysis.

3. **Super-Resolution Enhancement**  
   - Low-resolution images are enhanced using **Real-ESRGAN** (based on RRDBNet from BasicSR).  
   - This improves small-text or icon visibility before comparison.

4. **Difference Highlighting & Classification**  
   - Uses pixel-wise difference masks and connected component analysis to classify shifts as *global* or *localized*.

5. **Report Generation**  
   - Annotates the original HTML report with:  
     - Highlighted difference images  
     - AI verdicts and status tags  
     - Interactive feedback dropdowns  
     - Summary table with clickable links  
     - KO Check section for failed test conditions

6. **Output**  
   - Generates `aiAnalysisV2Report_<variant>.html` inside the `/output` folder.

---

## üß© Folder Structure
```
üì¶ Project Root
‚îÇ
‚îú‚îÄ‚îÄ üìÇ input/                    # Contains variant-specific folders with HTML + images
‚îú‚îÄ‚îÄ üìÇ output/                   # AI-annotated HTML reports are saved here
‚îÇ
‚îú‚îÄ‚îÄ api_handler.py               # Handles Mistral API requests for cloud-based comparison
‚îú‚îÄ‚îÄ local_model.py               # Local fallback image analysis model
‚îú‚îÄ‚îÄ main.ipynb                   # Primary Jupyter notebook orchestrating the workflow
‚îÇ
‚îú‚îÄ‚îÄ api_key.txt                  # Stores your Mistral API key (if available)
‚îú‚îÄ‚îÄ config_path.txt              # Stores variant and directory path templates
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îÇ
‚îî‚îÄ‚îÄ pkg_instl_files/             # (Create manually) to store external models like Real-ESRGAN & BasicSR
```

---

## üß† Key Libraries and Why They‚Äôre Used

| Library | Purpose |
|----------|----------|
| **BeautifulSoup (bs4)** | Parse and modify HTML reports for annotation |
| **OpenCV (cv2)** | Image difference detection, clustering, and mask generation |
| **Pillow (PIL)** | Image handling and compositing |
| **NumPy** | Numerical computations and mask operations |
| **Torch** | Runs Real-ESRGAN and local models |
| **Real-ESRGAN** | Super-resolution enhancement for small or low-quality screenshots |
| **BasicSR** | Provides RRDBNet backbone architecture used by Real-ESRGAN |
| **Requests** | Handles API communication with Mistral cloud model |
| **Mistral API** | Performs semantic-level image difference reasoning when API key is provided |

---

## üåê External Libraries to Download Manually

Some dependencies are **not available on PyPI** and must be cloned manually.

1. **Real-ESRGAN**
   ```bash
   git clone https://github.com/xinntao/Real-ESRGAN.git
   ```
   **Model Weights Path:**  
   `Path_to/Real-ESRGAN-master/realesrgan/weights/RealESRGAN_x4plus.pth`

2. **BasicSR v1.4.2**
   ```bash
   git clone -b v1.4.2 https://github.com/xinntao/BasicSR.git
   ```

> ‚ö†Ô∏è After downloading these repositories, update their paths in your code as needed.

---

## üß≠ Instructions to Run the Project

### 1. Clone the Repository
```bash
git clone <your_repo_url>
cd <your_repo_name>
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

Also ensure **Real-ESRGAN** and **BasicSR v1.4.2** are manually cloned as described above.

### 3. Configure Paths
Edit `config_path.txt` to set up your variant name and directory structure. Example:
```
variant = Captur_Regression_Tests_globalTestReport
report_path_template = ./input/{variant}/globalTestReport.html
image_dir_template = ./input/{variant}/images
output_dir = ./output
relative_image_path_template = ../input/{variant}/images
```

### 4. (Optional) Add Mistral API Key
Add your API key to `api_key.txt` (keep this file private):
```
sk-xxxxxxxxxxxxxxxxxxxxxxxx
```

If `api_key.txt` is missing or empty, the code automatically falls back to the **local model**.

### 5. Run the Notebook
Open `main.ipynb` in Jupyter Notebook or VSCode and run all cells.

### 6. Output
- The annotated HTML report will be saved inside `/output` as:  
  `aiAnalysisV2Report_<variant>.html`
- Open it in your browser to explore:
  - **Clickable summary table**
  - **Grouped status sections**
  - **KO checks**
  - **Interactive feedback panel**

---

## üíæ Example Output
- `aiAnalysisV2Report_Captur.html`
- `/output/img/` ‚Üí Difference-highlighted images

---

## üöÄ Future Improvements
- Integrate multilingual OCR-based checks using PaddleOCR  
- Add CLIP-based local semantic comparison  
- Enable cloud-based batch parallelization for large test suites  
- Add web dashboard view for analytics

---

## üë®‚Äçüíª Author
**Kanishk Mishra**  
*Former* AI Intern @ RNTBCI  
Focused on visual difference detection and semantic validation in automotive test automation.

